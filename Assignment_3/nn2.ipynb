{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from Neural_Net import boxplots, dataCleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = pd.read_csv(\"LBW_Dataset.csv\")\n",
    "dataset_temp = dataCleaning(dataset_temp)\n",
    "\n",
    "# features is a dataframe containing all the different features (attributes) of our dataset\n",
    "features = dataset_temp[['Community','Age','Weight','Delivery phase','HB','IFA','BP','Education','Residence']] # Copy isn't needed lol\n",
    "\n",
    "# labels is a dataframe containing the corresponding results that we try to predit using the NN\n",
    "labels = dataset_temp['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) #we use random.seed so that we can get the same random values whenever executed\n",
    "weights = np.random.rand(9,96) #9 since we have 9 attributes\n",
    "bias = np.random.rand(96) #randomly choose any bias value\n",
    "learning_rate = 0.05 #usually 0.05 is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"D://PESU//Sem 5//Machine Intelligence//MI_Assignment//Assignment_3//\"\n",
    "dataset = pd.read_csv(\"Clean_LBW_Data.csv\")\n",
    "dataset = dataCleaning(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def der_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def MSE(y_hat, y):\n",
    "    return np.mean(np.square(y-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(x_size, h_size, y_size):\n",
    "    np.random.seed(1)\n",
    "    W1 = np.random.randn(h_size, x_size) * 0.01\n",
    "    b1 = np.zeros(shape=(h_size, 1))\n",
    "    W2 = np.random.randn(y_size, h_size) * 0.01\n",
    "    b2 = np.zeros(shape=(y_size, 1))\n",
    "    dict_init = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    return dict_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(A_prev,act,W,b):\n",
    "    if act == \"relu\":\n",
    "        f = np.dot(W, A_prev) + b\n",
    "        #dict_fprop = {\"A_prev\": A_prev, \"W\": W, \"b\": b}\n",
    "        A = relu(f)\n",
    "    elif act == \"sigmoid\":\n",
    "        f = np.dot(W, A_prev) + b\n",
    "        #dict_fprop = {\"A_prev\": A_prev, \"W\": W, \"b\": b}\n",
    "        A = sigmoid(f)\n",
    "    dict_fprop = {\"A_prev\": A_prev, \"A\": A, \"W\": W, \"b\": b}\n",
    "    return A, dict_fprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y_hat,Y):\n",
    "    error = MSE(Y_hat, Y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(dA, dict_fprop):\n",
    "    A_prev = dict_fprop[\"A_prev\"]\n",
    "    A = dict_fprop[\"A\"]\n",
    "    W = dict_fprop[\"W\"]\n",
    "    b = dict_fprop[\"b\"]\n",
    "    #dW = np.dot(dZ, cache[0].T) / m\n",
    "    #db = np.squeeze(np.sum(dZ, axis=1, keepdims=True)) / m\n",
    "    #dA_prev = np.dot(cache[1].T, dZ) !!!!! I DONT KNOW THISSSSSSSSSSS \n",
    "    if act == \"relu\":\n",
    "        df = der_relu(dA) #!!!!! HAVE TO CODE THIS\n",
    "    elif act == \"sigmoid\":\n",
    "        df = der_sigmoid(dA)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(dict_init, dA, dW, db, lr):\n",
    "#MESSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMESSSSSSSSSSSSSSSSSSSSSS      \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    dict_init[\"W1\"]=dict_init[\"W1\"] - lr * dW\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (â‰ˆ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n",
      "Error =  0.75\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100): #x times the model is trained. we can choose different value based on our error.\n",
    "    inputs = features\n",
    "    xDOTw = np.dot(features, weights) + bias # dot product of xi.wi\n",
    "    #print(xDOTw)\n",
    "    netk = sigmoid(xDOTw)\n",
    "    labels = np.array(labels)\n",
    "    #print(type(netk))\n",
    "    #print(type(labels))\n",
    "    \n",
    "    #back propagation begins\n",
    "    error = MSE(netk,labels)\n",
    "    print(\"Error = \", error)\n",
    "    \n",
    "    # dE/dw = dE/dOk * dOk/dnetk * dnetk/dw\n",
    "    dE_dOk = error # dE/dOk\n",
    "    dok_dnetk = derivative_sigmoid(netk) #dOk/dnetk\n",
    "    dz_dw = dE_dOk * dok_dnetk # the derivative with respect to any weight is simply the corresponding input\n",
    "\n",
    "    inputs = features.T #transpose of the matrix\n",
    "    weights -= learning_rate * np.dot(inputs, dz_dw)\n",
    "\n",
    "    #print(dz_dw)\n",
    "    for num in dz_dw:\n",
    "        bias -= learning_rate * num\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
