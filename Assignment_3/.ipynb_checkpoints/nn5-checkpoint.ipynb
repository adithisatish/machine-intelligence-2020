{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from Neural_Net import boxplots, dataCleaning\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = pd.read_csv(\"LBW_Dataset.csv\")\n",
    "dataset_temp = dataCleaning(dataset_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features is a dataframe containing all the different features (attributes) of our dataset\n",
    "features = dataset_temp[['Community','Age','Weight','Delivery phase','HB','IFA','BP','Education','Residence']] # Copy isn't needed lol\n",
    "# labels is a dataframe containing the corresponding results that we try to predit using the NN\n",
    "labels = dataset_temp[['Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Seed the random number generator\n",
    "        np.random.seed(1)\n",
    "        self.lr = 0.02\n",
    "        # Set synaptic weights to a 9x1 matrix,\n",
    "        # with values from -1 to 1 and mean 0\n",
    "        self.input_hidden_weights = 2 * np.random.random((9, 32)) - 1\n",
    "        self.output_hidden_weights = 2 * np.random.random((32,1)) - 1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return ((np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))\n",
    "    \n",
    "    def tanh_derivative(self, x):\n",
    "        return (1-(self.tanh(x))**2)\n",
    "\n",
    "    def train(self, X, Y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            # Pass training set through the neural network\n",
    "            # output = self.think(X)\n",
    "            # X = X.astype(float)\n",
    "            h = np.dot(X,self.input_hidden_weights)\n",
    "            Ah = self.tanh(h)\n",
    "            h2 = np.dot(Ah,self.output_hidden_weights)\n",
    "            Yhat = self.sigmoid(h2)\n",
    "            # Calculate the error rate (MSE DERIVATIVE)\n",
    "            error = np.mean(np.square(Y-Yhat))\n",
    "            #print(epoch,error)\n",
    "            grad_output_hidden_weights = np.dot(Ah.T,(Y-Yhat)*self.sigmoid_derivative(h2))\n",
    "            grad_input_hidden_weights = np.dot(X.T,np.dot((Y-Yhat)*self.sigmoid_derivative(h2),self.output_hidden_weights.T)*self.tanh_derivative(h))\n",
    "            self.output_hidden_weights += self.lr * grad_output_hidden_weights\n",
    "            self.input_hidden_weights += self.lr * grad_input_hidden_weights\n",
    "            # Multiply error by input and gradient of the sigmoid function\n",
    "            # Less confident weights are adjusted more through the nature of the function\n",
    "            # adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "            # Adjust synaptic weights\n",
    "            # self.synaptic_weights += adjustments\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Pass inputs through the neural network to get output\n",
    "        \"\"\"\n",
    "        # X = X.astype(float)\n",
    "        h = np.dot(X,self.input_hidden_weights)\n",
    "        Ah = self.sigmoid(h)\n",
    "        h2 = np.dot(Ah,self.output_hidden_weights)\n",
    "        Yhat = self.sigmoid(h2)\n",
    "        return Yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 9) (96, 1)\n",
      "Starting Training\n",
      "accuracy : 0.8\n",
      "Confusion Matrix : \n",
      "[[0, 4], [0, 16]]\n",
      "\n",
      "\n",
      "Precision : 0.8\n",
      "Recall : 1.0\n",
      "F1 SCORE : 0.888888888888889\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Initialize the single neuron neural network\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    # print(\"Random starting synaptic weights: \")\n",
    "    # print(neural_network.input_hidden_weights)\n",
    "    # print(neural_network.output_hidden_weights)\n",
    "    # The training set, with 4 examples consisting of 3\n",
    "    # input values and 1 output value\n",
    "    X = np.array(features, dtype=np.float128)\n",
    "    Y = np.array(labels, dtype=np.float128)    \n",
    "    print(X.shape, Y.shape)\n",
    "    print(\"Starting Training\")\n",
    "    # split into train test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "    # Train the neural network\n",
    "    neural_network.train(X_train, Y_train, 5000)\n",
    "    # print(\"Synaptic weights after training: \")\n",
    "    # print(neural_network.input_hidden_weights)\n",
    "    # print(neural_network.output_hidden_weights)\n",
    "    Yhat = neural_network.predict(X_test)\n",
    "    Y_hat = [1 if i>0.5 else 0 for i in Yhat]\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i,j in zip(Y_test,Y_hat):\n",
    "        if i==1 and j==1:\n",
    "            TP+=1\n",
    "        elif i==0 and j==0:\n",
    "            TN+=1\n",
    "        elif i==1 and j==0:\n",
    "            FN+=1\n",
    "        elif i==0 and j==1:\n",
    "            FP+=1\n",
    "            \n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    print(f\"accuracy : {accuracy}\")\n",
    "    cm=[[0,0],[0,0]]\n",
    "    cm[0][0]=TN\n",
    "    cm[0][1]=FP\n",
    "    cm[1][0]=FN\n",
    "    cm[1][1]=TP\n",
    "    p= TP/(TP+FP)\n",
    "    r= TP/(TP+FN)\n",
    "    f1=(2*p*r)/(p+r)\n",
    "    print(\"Confusion Matrix : \")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Precision : {p}\")\n",
    "    print(f\"Recall : {r}\")\n",
    "    print(f\"F1 SCORE : {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
