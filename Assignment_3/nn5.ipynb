{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from Neural_Net import boxplots, dataCleaning, feature_scaling, normalization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = pd.read_csv(\"LBW_Dataset.csv\")\n",
    "dataset_temp = dataCleaning(dataset_temp)\n",
    "# dataset_temp[\"Result\"] = 0\n",
    "# dataset_temp1 = feature_scaling(dataset_temp)\n",
    "# dataset_temp2 = normalization(dataset_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Community   Age  Weight  Delivery phase   HB  IFA     BP  Education  \\\n0          1  21.0    42.0             1.0  9.2    1  1.375        5.0   \n1          1  21.0    45.0             1.0  8.8    1  1.500        5.0   \n2          1  21.0    45.0             1.0  9.2    1  2.125        5.0   \n3          1  21.0    45.0             1.0  8.0    1  1.375        5.0   \n4          1  24.0    33.0             1.0  9.3    1  1.571        5.0   \n\n   Residence  Result  \n0        1.0       0  \n1        1.0       0  \n2        1.0       0  \n3        1.0       0  \n4        1.0       0  \n"
     ]
    }
   ],
   "source": [
    "# list(dataset_temp.keys())\n",
    "print(dataset_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Community       Age    Weight  Delivery phase        HB     IFA        BP  \\\n",
       "0  -0.392361 -0.131944 -0.088988       -0.020833  0.027165  0.3125 -0.024852   \n",
       "1  -0.392361 -0.131944 -0.003274       -0.020833 -0.051266  0.3125 -0.014990   \n",
       "2  -0.392361 -0.131944 -0.003274       -0.020833  0.027165  0.3125  0.034319   \n",
       "3  -0.392361 -0.131944 -0.003274       -0.020833 -0.208129  0.3125 -0.024852   \n",
       "4  -0.392361  0.010913 -0.346131       -0.020833  0.046773  0.3125 -0.009389   \n",
       "\n",
       "   Education  Residence  Result  \n",
       "0        1.0  -0.135417   -0.75  \n",
       "1        1.0  -0.135417   -0.75  \n",
       "2        1.0  -0.135417   -0.75  \n",
       "3        1.0  -0.135417   -0.75  \n",
       "4        1.0  -0.135417   -0.75  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Community</th>\n      <th>Age</th>\n      <th>Weight</th>\n      <th>Delivery phase</th>\n      <th>HB</th>\n      <th>IFA</th>\n      <th>BP</th>\n      <th>Education</th>\n      <th>Residence</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.392361</td>\n      <td>-0.131944</td>\n      <td>-0.088988</td>\n      <td>-0.020833</td>\n      <td>0.027165</td>\n      <td>0.3125</td>\n      <td>-0.024852</td>\n      <td>1.0</td>\n      <td>-0.135417</td>\n      <td>-0.75</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.392361</td>\n      <td>-0.131944</td>\n      <td>-0.003274</td>\n      <td>-0.020833</td>\n      <td>-0.051266</td>\n      <td>0.3125</td>\n      <td>-0.014990</td>\n      <td>1.0</td>\n      <td>-0.135417</td>\n      <td>-0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.392361</td>\n      <td>-0.131944</td>\n      <td>-0.003274</td>\n      <td>-0.020833</td>\n      <td>0.027165</td>\n      <td>0.3125</td>\n      <td>0.034319</td>\n      <td>1.0</td>\n      <td>-0.135417</td>\n      <td>-0.75</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.392361</td>\n      <td>-0.131944</td>\n      <td>-0.003274</td>\n      <td>-0.020833</td>\n      <td>-0.208129</td>\n      <td>0.3125</td>\n      <td>-0.024852</td>\n      <td>1.0</td>\n      <td>-0.135417</td>\n      <td>-0.75</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.392361</td>\n      <td>0.010913</td>\n      <td>-0.346131</td>\n      <td>-0.020833</td>\n      <td>0.046773</td>\n      <td>0.3125</td>\n      <td>-0.009389</td>\n      <td>1.0</td>\n      <td>-0.135417</td>\n      <td>-0.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dataset_temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features is a dataframe containing all the different features (attributes) of our dataset\n",
    "features = dataset_temp[['Community','Age','Weight','Delivery phase','HB','IFA','BP', 'Education','Residence']]\n",
    "# labels is a dataframe containing the corresponding results that we try to predit using the NN\n",
    "labels = dataset_temp[['Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Seed the random number generator\n",
    "        np.random.seed(1)\n",
    "        self.lr = 0.01\n",
    "        # Set the weights -> 20 hidden layer neurons \n",
    "        self.input_hidden_weights = np.random.randn(9, 20)*0.03\n",
    "        self.output_hidden_weights = np.random.randn(20,1)*0.03\n",
    "        # Setting the bias \n",
    "        self.input_bias = np.random.randn(1, 20)*0.0005\n",
    "        self.output_bias = np.random.randn(1, 1)*0.0005\n",
    "\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return ((np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))\n",
    "    \n",
    "    def tanh_derivative(self, x):\n",
    "        return (1-(self.tanh(x))**2)\n",
    "\n",
    "    def train(self, X, Y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            X_length = len(X)\n",
    "            error = 0\n",
    "            # Pass training set through the neural network row by row\n",
    "            for x, y in zip(X, Y):\n",
    "                \n",
    "                x = np.array([x])\n",
    "               \n",
    "                # Layer 1\n",
    "                # x : input\n",
    "                # Ah : output\n",
    "                h = np.dot(x, self.input_hidden_weights) + self.input_bias\n",
    "                Ah = self.tanh(h)\n",
    "                \n",
    "                # Layer 2:\n",
    "                # Ah : input\n",
    "                # Yhat : final output\n",
    "                h2 = np.dot(Ah, self.output_hidden_weights) + self.output_bias\n",
    "                Yhat = self.sigmoid(h2)\n",
    "                \n",
    "                # Calculate the error rate (MSE DERIVATIVE)\n",
    "                # summ : wi*xi + bi\n",
    "                # error: d(loss)/d(output)\n",
    "                # activation error: d(loss)/d(o) * f'(summ)\n",
    "                # weights: d(loss)/d(w1): d(loss)/d(output) * d(out)/d(summ) * d(summ)/s(wi) : activation error * d(summ)/s(wi) : activation error * input\n",
    "                # bias: d(loss)/d(bias) : f'(x) * d(summ)/d(b) = f'(x)\n",
    "                # input: d(loss)/d(input) : d(loss)/d(summ) * d(summ)/d(in) = f'(x) * wi\n",
    "                error += np.mean(np.square(y-Yhat))\n",
    "                # derivatives \n",
    "                der_error = y-Yhat\n",
    "                # (der_error) * self.sigmoid_derivative(h2) is the activation error\n",
    "                act_error_1 = (der_error) * self.sigmoid_derivative(h2)\n",
    "                backprop_error = np.dot((der_error) * self.sigmoid_derivative(h2), self.output_hidden_weights.T)\n",
    "                act_error_2 = (backprop_error) * self.tanh_derivative(h)\n",
    "\n",
    "                # Differential of d(xi*wi + bi)/d(wi) = xi (input to any layer) (Here input to L2 is Ah)\n",
    "                grad_output_hidden_weights = np.dot(Ah.T, act_error_1)\n",
    "                # (Here input to L1 is x)\n",
    "                grad_input_hidden_weights = np.dot(x.T, act_error_2)\n",
    "                # Differential of d(xi*wi + bi)/d(bi) = 1\n",
    "                grad_output_bias = act_error_1\n",
    "                grad_input_bias = act_error_2\n",
    "\n",
    "\n",
    "                # updation of the weights and biases\n",
    "                self.output_hidden_weights += self.lr * grad_output_hidden_weights\n",
    "                self.input_hidden_weights += self.lr * grad_input_hidden_weights\n",
    "                self.output_bias += self.lr * grad_output_bias\n",
    "                self.input_bias += self.lr * grad_input_bias\n",
    "            if(not epoch%100):\n",
    "                print(epoch, error/X_length)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Pass inputs through the neural network to get output\n",
    "        \"\"\"\n",
    "        h = np.dot(X,self.input_hidden_weights) + self.input_bias\n",
    "        Ah = self.sigmoid(h)\n",
    "        h2 = np.dot(Ah,self.output_hidden_weights) + self.output_bias\n",
    "        Yhat = self.sigmoid(h2)\n",
    "        return Yhat\n",
    "    \n",
    "#NOT SURE IF WE SHOULD ADD MORE LAYERS, PLS CHECK IT OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(96, 9) (96, 1)\n",
      "Starting Training\n",
      "0 0.21820887502282973\n",
      "100 0.16945625843968556\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "accuracy : 0.85\n",
      "Confusion Matrix : \n",
      "[[1, 3], [0, 16]]\n",
      "\n",
      "\n",
      "Precision : 0.8421052631578947\n",
      "Recall : 1.0\n",
      "F1 SCORE : 0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Initialize the single neuron neural network\n",
    "    neural_network = NeuralNetwork()\n",
    "    X = np.array(features, dtype=np.longdouble)\n",
    "    Y = np.array(labels, dtype=np.longdouble)    \n",
    "    print(X.shape, Y.shape)\n",
    "    print(\"Starting Training\")\n",
    "    # split into train test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "    # Train the neural network\n",
    "    neural_network.train(X_train, Y_train, 200)\n",
    "    Yhat = neural_network.predict(X_test)\n",
    "    Y_hat = [1 if i>0.6 else 0 for i in Yhat]\n",
    "    print(Y_test, Y_hat)\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i,j in zip(Y_test,Y_hat):\n",
    "        if i==1 and j==1:\n",
    "            TP+=1\n",
    "        elif i==0 and j==0:\n",
    "            TN+=1\n",
    "        elif i==1 and j==0:\n",
    "            FN+=1\n",
    "        elif i==0 and j==1:\n",
    "            FP+=1\n",
    "            \n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    print(f\"accuracy : {accuracy}\")\n",
    "    cm=[[0,0],[0,0]]\n",
    "    cm[0][0]=TN\n",
    "    cm[0][1]=FP\n",
    "    cm[1][0]=FN\n",
    "    cm[1][1]=TP\n",
    "    # May need to add try except to avoid divide by 0\n",
    "    p= TP/(TP+FP)\n",
    "    r= TP/(TP+FN)\n",
    "    f1=(2*p*r)/(p+r)\n",
    "    print(\"Confusion Matrix : \")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Precision : {p}\")\n",
    "    print(f\"Recall : {r}\")\n",
    "    print(f\"F1 SCORE : {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, explained_variance_score\n",
    "\n",
    "def model_metrics(y_test,pred):\n",
    "    # print(\"R^2:\", score*100, \"%\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test,pred)*100,\"%\")\n",
    "    print(\"Precision:\",precision_score(y_test,pred)*100,\"%\")\n",
    "    print(\"Recall:\",recall_score(y_test,pred)*100,\"%\")\n",
    "    print(\"F1 Score:\",f1_score(y_test,pred)*100,\"%\")\n",
    "    print(\"MSE:\",mean_squared_error(y_test,pred)*100,\"%\")\n",
    "    print(\"Explained Variance Regression Score:\", explained_variance_score(y_test,pred))\n",
    "    # auc_roc(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Performance Metrics:\n\nAccuracy: 78.94736842105263 %\nPrecision: 78.57142857142857 %\nRecall: 98.21428571428571 %\nF1 Score: 87.3015873015873 %\nMSE: 21.052631578947366 %\nExplained Variance Regression Score: 0.08928571428571441\n\n\n-------------------------------\n\nTest Set Performance Metrics:\n\nAccuracy: 85.0 %\nPrecision: 84.21052631578947 %\nRecall: 100.0 %\nF1 Score: 91.42857142857143 %\nMSE: 15.0 %\nExplained Variance Regression Score: 0.2031250000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set Performance Metrics:\\n\")\n",
    "Yh_train = neural_network.predict(X_train)\n",
    "Yh_train = [1 if i>0.6 else 0 for i in Yh_train]\n",
    "model_metrics(Y_train,Yh_train)\n",
    "print(\"\\n\\n-------------------------------\\n\")\n",
    "print(\"Test Set Performance Metrics:\\n\")\n",
    "model_metrics(Y_test,Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}