{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from Neural_Net import boxplots, dataCleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = pd.read_csv(\"LBW_Dataset.csv\")\n",
    "dataset_temp = dataCleaning(dataset_temp)\n",
    "\n",
    "# features is a dataframe containing all the different features (attributes) of our dataset\n",
    "features = dataset_temp[['Community','Age','Weight','Delivery phase','HB','IFA','BP','Education','Residence']].copy()\n",
    "\n",
    "# labels is a dataframe containing the corresponding results that we try to predit using the NN\n",
    "labels = dataset_temp['Result'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) #we use random.seed so that we can get the same random values whenever executed\n",
    "weights = np.random.rand(9,96) #9 since we have 9 attributes\n",
    "bias = np.random.rand(96) #randomly choose any bias value\n",
    "learning_rate = 0.05 #usually 0.05 is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"D://PESU//Sem 5//Machine Intelligence//MI_Assignment//Assignment_3//\"\n",
    "dataset = pd.read_csv(\"Clean_LBW_Data.csv\")\n",
    "dataset = dataCleaning(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-939dd19ee067>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =  -5.0649247720691015e-05\n",
      "Error =  -5.0620637011444813e-05\n",
      "Error =  -5.059206697144436e-05\n",
      "Error =  -5.056353750187981e-05\n",
      "Error =  -5.053504851859625e-05\n",
      "Error =  -5.050659993222073e-05\n",
      "Error =  -5.047819164127887e-05\n",
      "Error =  -5.0449823569609364e-05\n",
      "Error =  -5.042149562040077e-05\n",
      "Error =  -5.0393207705501375e-05\n",
      "Error =  -5.036495972732258e-05\n",
      "Error =  -5.033675161303375e-05\n",
      "Error =  -5.0308583258495965e-05\n",
      "Error =  -5.0280454586326684e-05\n",
      "Error =  -5.025236550326717e-05\n",
      "Error =  -5.022431591916732e-05\n",
      "Error =  -5.019630575231471e-05\n",
      "Error =  -5.016833491111594e-05\n",
      "Error =  -5.0140403309972825e-05\n",
      "Error =  -5.011251085818014e-05\n",
      "Error =  -5.008465747335933e-05\n",
      "Error =  -5.005684307357594e-05\n",
      "Error =  -5.00290675569115e-05\n",
      "Error =  -5.000133085653058e-05\n",
      "Error =  -4.997363287451151e-05\n",
      "Error =  -4.9945973528253695e-05\n",
      "Error =  -4.991835273426837e-05\n",
      "Error =  -4.989077040851164e-05\n",
      "Error =  -4.986322646283181e-05\n",
      "Error =  -4.983572081296295e-05\n",
      "Error =  -4.980825337563832e-05\n",
      "Error =  -4.978082407125495e-05\n",
      "Error =  -4.97534328121052e-05\n",
      "Error =  -4.9726079513701116e-05\n",
      "Error =  -4.9698764096883785e-05\n",
      "Error =  -4.967148647239128e-05\n",
      "Error =  -4.96442465680591e-05\n",
      "Error =  -4.9617044292848966e-05\n",
      "Error =  -4.958987956615868e-05\n",
      "Error =  -4.9562752307164004e-05\n",
      "Error =  -4.9535662433042305e-05\n",
      "Error =  -4.950860986485672e-05\n",
      "Error =  -4.948159451623191e-05\n",
      "Error =  -4.945461631478132e-05\n",
      "Error =  -4.942767517290836e-05\n",
      "Error =  -4.9400771013341505e-05\n",
      "Error =  -4.9373903753480164e-05\n",
      "Error =  -4.934707331527566e-05\n",
      "Error =  -4.9320279615239215e-05\n",
      "Error =  -4.9293522579985094e-05\n",
      "Error =  -4.926680212558043e-05\n",
      "Error =  -4.924011817608598e-05\n",
      "Error =  -4.921347064956727e-05\n",
      "Error =  -4.918685947141732e-05\n",
      "Error =  -4.916028455659305e-05\n",
      "Error =  -4.913374583270791e-05\n",
      "Error =  -4.910724322049198e-05\n",
      "Error =  -4.908077664411703e-05\n",
      "Error =  -4.905434601842895e-05\n",
      "Error =  -4.90279512774805e-05\n",
      "Error =  -4.900159233811596e-05\n",
      "Error =  -4.897526911806782e-05\n",
      "Error =  -4.894898155383132e-05\n",
      "Error =  -4.892272955492327e-05\n",
      "Error =  -4.88965130571728e-05\n",
      "Error =  -4.887033197853441e-05\n",
      "Error =  -4.884418624284681e-05\n",
      "Error =  -4.881807577639119e-05\n",
      "Error =  -4.879200050444954e-05\n",
      "Error =  -4.876596034986136e-05\n",
      "Error =  -4.873995524135033e-05\n",
      "Error =  -4.871398510164493e-05\n",
      "Error =  -4.8688049859690885e-05\n",
      "Error =  -4.8662149433442714e-05\n",
      "Error =  -4.8636283755731924e-05\n",
      "Error =  -4.861045275350584e-05\n",
      "Error =  -4.8584656346384314e-05\n",
      "Error =  -4.855889446520045e-05\n",
      "Error =  -4.853316704123145e-05\n",
      "Error =  -4.8507473993764094e-05\n",
      "Error =  -4.8481815257850336e-05\n",
      "Error =  -4.845619075277696e-05\n",
      "Error =  -4.843060041326286e-05\n",
      "Error =  -4.8405044160704236e-05\n",
      "Error =  -4.8379521930042024e-05\n",
      "Error =  -4.835403364589208e-05\n",
      "Error =  -4.832857923864342e-05\n",
      "Error =  -4.8303158633022925e-05\n",
      "Error =  -4.8277771759752675e-05\n",
      "Error =  -4.8252418551553156e-05\n",
      "Error =  -4.822709893193e-05\n",
      "Error =  -4.8201812836823343e-05\n",
      "Error =  -4.8176560190738016e-05\n",
      "Error =  -4.815134092484019e-05\n",
      "Error =  -4.8126154974736934e-05\n",
      "Error =  -4.8101002258382763e-05\n",
      "Error =  -4.807588271948937e-05\n",
      "Error =  -4.8050796282228525e-05\n",
      "Error =  -4.802574287732231e-05\n",
      "Error =  -4.8000722439822674e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100): #x times the model is trained. we can choose different value based on our error.\n",
    "    inputs = features\n",
    "    xDOTw = np.dot(features, weights) + bias # dot product of xi.wi\n",
    "    #print(xDOTw)\n",
    "    netk = sigmoid(xDOTw)\n",
    "    labels = np.array(labels)\n",
    "    #print(type(netk))\n",
    "    #print(type(labels))\n",
    "    \n",
    "    #back propagation begins\n",
    "    error = netk - labels\n",
    "    print(\"Error = \", error.sum())\n",
    "    \n",
    "    # dE/dw = dE/dOk * dOk/dnetk * dnetk/dw\n",
    "    dE_dOk = error # dE/dOk\n",
    "    dok_dnetk = derivative_sigmoid(netk) #dOk/dnetk\n",
    "    dz_dw = dE_dOk * dok_dnetk # the derivative with respect to any weight is simply the corresponding input\n",
    "\n",
    "    inputs = features.T #transpose of the matrix\n",
    "    weights -= learning_rate * np.dot(inputs, dz_dw)\n",
    "\n",
    "    #print(dz_dw)\n",
    "    for num in dz_dw:\n",
    "        bias -= learning_rate * num\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
